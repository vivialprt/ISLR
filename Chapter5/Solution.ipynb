{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  student      balance        income\n",
       "0        0        0   729.526495  44361.625074\n",
       "1        0        1   817.180407  12106.134700\n",
       "2        0        0  1073.549164  31767.138947\n",
       "3        0        0   529.250605  35704.493935\n",
       "4        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = '../datasets/Default.csv'\n",
    "data = pd.read_csv(dataset_file)\n",
    "data.default = data.default.apply(lambda v: 1 if v == 'Yes' else 0)\n",
    "data.student = data.student.apply(lambda v: 1 if v == 'Yes' else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [default, student, balance, income]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      9667\n",
      "           1       0.74      0.32      0.45       333\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.86      0.66      0.72     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "[[9629   38]\n",
      " [ 225  108]]\n",
      "0.9737\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(data[['balance', 'income']], data['default'])\n",
    "print(classification_report(data['default'], model.predict(data[['balance', 'income']])))\n",
    "print(confusion_matrix(data['default'], model.predict(data[['balance', 'income']])))\n",
    "print(accuracy_score(data['default'], model.predict(data[['balance', 'income']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      4841\n",
      "           1       0.00      0.00      0.00       159\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.48      0.50      0.49      5000\n",
      "weighted avg       0.94      0.97      0.95      5000\n",
      "\n",
      "[[4839    2]\n",
      " [ 159    0]]\n",
      "0.9678\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = train_test_split(data, random_state=1, train_size=0.5)\n",
    "model2 = LogisticRegression().fit(train_set[['balance', 'income']], train_set['default'])\n",
    "print(classification_report(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(confusion_matrix(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(accuracy_score(val_set['default'], model2.predict(val_set[['balance', 'income']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      4846\n",
      "           1       0.00      0.00      0.00       154\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.48      0.50      0.49      5000\n",
      "weighted avg       0.94      0.97      0.95      5000\n",
      "\n",
      "[[4844    2]\n",
      " [ 154    0]]\n",
      "0.9688\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = train_test_split(data, random_state=2, train_size=0.5)\n",
    "model2 = LogisticRegression().fit(train_set[['balance', 'income']], train_set['default'])\n",
    "print(classification_report(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(confusion_matrix(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(accuracy_score(val_set['default'], model2.predict(val_set[['balance', 'income']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      4831\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.48      0.50      0.49      5000\n",
      "weighted avg       0.93      0.97      0.95      5000\n",
      "\n",
      "[[4830    1]\n",
      " [ 169    0]]\n",
      "0.966\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = train_test_split(data, random_state=3, train_size=0.5)\n",
    "model2 = LogisticRegression().fit(train_set[['balance', 'income']], train_set['default'])\n",
    "print(classification_report(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(confusion_matrix(val_set['default'], model2.predict(val_set[['balance', 'income']])))\n",
    "print(accuracy_score(val_set['default'], model2.predict(val_set[['balance', 'income']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are very similar, but not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4837\n",
      "           1       0.74      0.37      0.50       163\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.86      0.68      0.74      5000\n",
      "weighted avg       0.97      0.98      0.97      5000\n",
      "\n",
      "[[4816   21]\n",
      " [ 102   61]]\n",
      "0.9754\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = train_test_split(data, random_state=4, train_size=0.5)\n",
    "model3 = LogisticRegression().fit(train_set[['balance', 'income', 'student']], train_set['default'])\n",
    "pred_y = model3.predict(val_set[['balance', 'income', 'student']])\n",
    "print(classification_report(val_set['default'], pred_y))\n",
    "print(confusion_matrix(val_set['default'], pred_y))\n",
    "print(accuracy_score(val_set['default'], pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first it seems, that including `student` variable only give approximately 1 percent increase in accuracy score, which could already be a good improvement, but also confusion matrix show that model now much more powerful in predicting default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>default</td>     <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 10 Sep 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:35:32</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th> <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>  <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 10 Sep 2020   Pseudo R-squ.:                  0.4594\n",
       "Time:                        09:35:32   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(data.default, sm.add_constant(data[['balance', 'income']])).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(data):\n",
    "    model = LogisticRegression().fit(data[['balance', 'income']], data['default'])\n",
    "    return model.intercept_[0], model.coef_[0][0], model.coef_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs2(data):\n",
    "    model = sm.Logit(data.default, sm.add_constant(data[['balance', 'income']])).fit(disp=False)\n",
    "    return model.params[0], model.params[1], model.params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0 SE: 0.43486607489744533\n",
      "B1 SE: 0.00023423457033904319\n",
      "B2 SE: 4.645095996902784e-06\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i in range(1000):\n",
    "    b.append(get_coefs2(resample(data)))\n",
    "\n",
    "print(f'B0 SE: {np.std([val[0] for val in b])}')\n",
    "print(f'B1 SE: {np.std([val[1] for val in b])}')\n",
    "print(f'B2 SE: {np.std([val[2] for val in b])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected standard errors obtained in both methods are very similar. Okay, I have a problem. Sklearn gives some strange values of intercept, thus yields huge variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today  Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270          0\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576          0\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514          1\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712          1\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = '../datasets/Weekly.csv'\n",
    "data = pd.read_csv(dataset_file)\n",
    "data.Direction = data.Direction.apply(lambda v: 1 if v == 'Up' else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.08      0.13       484\n",
      "           1       0.56      0.94      0.70       605\n",
      "\n",
      "    accuracy                           0.55      1089\n",
      "   macro avg       0.53      0.51      0.42      1089\n",
      "weighted avg       0.53      0.55      0.45      1089\n",
      "\n",
      "[[ 37 447]\n",
      " [ 38 567]]\n",
      "0.5546372819100092\n"
     ]
    }
   ],
   "source": [
    "model_base = LogisticRegression().fit(data[['Lag1', 'Lag2']], data['Direction'])\n",
    "pred_y = model_base.predict(data[['Lag1', 'Lag2']])\n",
    "print(classification_report(data['Direction'], pred_y))\n",
    "print(confusion_matrix(data['Direction'], pred_y))\n",
    "print(accuracy_score(data['Direction'], pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500459136822773"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = []\n",
    "for i in range(len(data)):\n",
    "    data_one_out = data.drop([i])\n",
    "    model = LogisticRegression().fit(data_one_out[['Lag1', 'Lag2']], data_one_out['Direction'])\n",
    "    pred_y = model.predict(data.iloc[i][['Lag1', 'Lag2']].values.reshape(1, -1))[0]\n",
    "    I.append(pred_y == data.iloc[i]['Direction'])\n",
    "np.mean(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error estimate is very high. We literally not far away from guessing. Also Errors don't differ too much from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.normal(size=100)\n",
    "y = x - 2 * x ** 2 + np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_n_ = 100, _p_ = 1  \n",
    "_Y_ = 1 * _X_ - 2 * _X_^2 + _e_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fea2e57d828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows quadratic relationship between X and Y with some noise.  \n",
    "As normal distribution suggests, almost all examples lie in between [-2 * sigma, 2 * sigma] (sigma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['x', 'y'])\n",
    "data.x = x\n",
    "data['x^2'] = x ** 2\n",
    "data['x^3'] = x ** 3\n",
    "data['x^4'] = x ** 4\n",
    "data.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple MSE     : 6.260764331604616\n",
      "Quadratic MSE  : 0.9142897072803658\n",
      "Cubic MSE      : 0.9268768781648802\n",
      "Biquadratic MSE: 0.8669116865881079\n"
     ]
    }
   ],
   "source": [
    "mse_array_1 = []\n",
    "for i in range(len(data)):\n",
    "    data_one_out = data.drop([i])\n",
    "    model = LinearRegression().fit(data_one_out['x'].values.reshape(-1, 1), data_one_out['y'])\n",
    "    pred_y = model.predict(data.iloc[i]['x'].reshape(1, -1))[0]\n",
    "    mse_array_1.append((data.iloc[i]['y'] - pred_y) ** 2)\n",
    "\n",
    "# quadratic   \n",
    "mse_array_2 = []\n",
    "for i in range(len(data)):\n",
    "    data_one_out = data.drop([i])\n",
    "    model = LinearRegression().fit(data_one_out[['x', 'x^2']], data_one_out['y'])\n",
    "    pred_y = model.predict(data.iloc[i][['x', 'x^2']].values.reshape(1, -1))[0]\n",
    "    mse_array_2.append((data.iloc[i]['y'] - pred_y) ** 2)\n",
    "\n",
    "# cubic\n",
    "mse_array_3 = []\n",
    "for i in range(len(data)):\n",
    "    data_one_out = data.drop([i])\n",
    "    model = LinearRegression().fit(data_one_out[['x', 'x^2', 'x^3']], data_one_out['y'])\n",
    "    pred_y = model.predict(data.iloc[i][['x', 'x^2', 'x^3']].values.reshape(1, -1))[0]\n",
    "    mse_array_3.append((data.iloc[i]['y'] - pred_y) ** 2)\n",
    "\n",
    "#biquadratic\n",
    "mse_array_4 = []\n",
    "for i in range(len(data)):\n",
    "    data_one_out = data.drop([i])\n",
    "    model = LinearRegression().fit(data_one_out[['x', 'x^2', 'x^3', 'x^4']], data_one_out['y'])\n",
    "    pred_y = model.predict(data.iloc[i][['x', 'x^2', 'x^3', 'x^4']].values.reshape(1, -1))[0]\n",
    "    mse_array_4.append((data.iloc[i]['y'] - pred_y) ** 2)\n",
    "\n",
    "print(f'Simple MSE     : {np.mean(mse_array_1)}')\n",
    "print(f'Quadratic MSE  : {np.mean(mse_array_2)}')\n",
    "print(f'Cubic MSE      : {np.mean(mse_array_3)}')\n",
    "print(f'Biquadratic MSE: {np.mean(mse_array_4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no sense in using different random seeds, because the process is full determined, LOOCV does not perform random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic and biquadratic models have the lowest error. Biquadratic is slightly better, due to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 10 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>1.24e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:28:46</td>     <th>  Log-Likelihood:    </th> <td> -130.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   271.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   284.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3140</td> <td>    0.136</td> <td>    2.311</td> <td> 0.023</td> <td>    0.044</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>     <td>    0.9127</td> <td>    0.183</td> <td>    4.999</td> <td> 0.000</td> <td>    0.550</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x^2</th>   <td>   -2.5445</td> <td>    0.248</td> <td>  -10.264</td> <td> 0.000</td> <td>   -3.037</td> <td>   -2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x^3</th>   <td>    0.0992</td> <td>    0.064</td> <td>    1.556</td> <td> 0.123</td> <td>   -0.027</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x^4</th>   <td>    0.1394</td> <td>    0.057</td> <td>    2.437</td> <td> 0.017</td> <td>    0.026</td> <td>    0.253</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.537</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.464</td> <th>  Jarque-Bera (JB):  </th> <td>   1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.238</td> <th>  Prob(JB):          </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.184</td> <th>  Cond. No.          </th> <td>    15.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.873\n",
       "Model:                            OLS   Adj. R-squared:                  0.867\n",
       "Method:                 Least Squares   F-statistic:                     163.0\n",
       "Date:                Thu, 10 Sep 2020   Prob (F-statistic):           1.24e-41\n",
       "Time:                        10:28:46   Log-Likelihood:                -130.63\n",
       "No. Observations:                 100   AIC:                             271.3\n",
       "Df Residuals:                      95   BIC:                             284.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3140      0.136      2.311      0.023       0.044       0.584\n",
       "x              0.9127      0.183      4.999      0.000       0.550       1.275\n",
       "x^2           -2.5445      0.248    -10.264      0.000      -3.037      -2.052\n",
       "x^3            0.0992      0.064      1.556      0.123      -0.027       0.226\n",
       "x^4            0.1394      0.057      2.437      0.017       0.026       0.253\n",
       "==============================================================================\n",
       "Omnibus:                        1.537   Durbin-Watson:                   2.100\n",
       "Prob(Omnibus):                  0.464   Jarque-Bera (JB):                1.088\n",
       "Skew:                          -0.238   Prob(JB):                        0.581\n",
       "Kurtosis:                       3.184   Cond. No.                         15.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(data['y'], sm.add_constant(data.drop(['y'], axis=1))).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values show that `x^2` and `x` are statistically significant. `x^4` is less significant in presense of `x^2`, but is also useful, which suggests that biquadratic model is more powerful on train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = '../datasets/Boston.csv'\n",
    "data = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.532806324110677, 0.40886114749753505)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat = data.medv.mean()\n",
    "se_hat = data.medv.std() / data.medv.size ** 0.5\n",
    "mu_hat, se_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard error is standard deviation of sample mean from true mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40902913677666564"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = [resample(data.medv).mean() for _ in range(1000)]\n",
    "np.std(mus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap standard error is very similar to estimated one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.73602166662129, 23.339415882785822)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mus) - 1.96 * np.std(mus), np.mean(mus) + 1.96 * np.std(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_hat = data.medv.median()\n",
    "med_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.43377610717347, 21.918023892826522)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meds = [resample(data.medv).median() for _ in range(1000)]\n",
    "np.mean(meds) - 1.96 * np.std(meds), np.mean(meds) + 1.96 * np.std(meds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`medv` median lies between (20.434, 21.918)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_hat = data.medv.quantile(0.1)\n",
    "perc_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.756975341988813, 13.722024658011186)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc = [resample(data.medv).quantile(0.1) for _ in range(1000)]\n",
    "np.mean(perc) - 1.96 * np.std(perc), np.mean(perc) + 1.96 * np.std(perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`medv` tenth percentile lies between (11.757, 13.722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
